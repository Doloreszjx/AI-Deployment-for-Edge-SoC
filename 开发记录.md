# phase 1： YOLOv8n Baseline 推理（Windows + CPU）
在Windows CPU环境下跑通YOLOv8你， 作为端侧部署的baseline
这个阶段不涉及任何SoC特定优化，主要用于建立后续模型转换，量化和算子优化的对比基线

**Q: 为什么不一开始就优化** </br>
因为端侧优化必须建立在可复现，可对比的baseline之上，否则无法量化每一步优化带来的收益

## 分析数据
### 数据1：
写入时间为：2026-01-06 16:19 \
Device: CPU \
Interface Time: 44.56 ms \
Memory Usage: 0.00 MB 

推理结果合理，YOLOv8n在Windows CPU上单张640X640， 40-60ms是常见的区间 \
**Memory Usage 为 0.00 MB** \
原因:
- psutil 读的是 RSS 增量
- YOLO 模型在：
初始化阶段已分配大部分内存;
单次 inference 不再显著增长
- Windows 内存回收策略 + Python GC \
→ 导致 delta ≈ 0

总结：
- 单次推理的内存增量在 Windows 上不明显，**模型参数**和**缓存**主要在*初始化阶段*完成分配，因此 RSS delta 接近 0，这是符合预期的。
- 真正端侧内存评估通常通过工具链统计 peak memory 或 allocator 级别数据，而非 Python 进程 delta

### 数据2：
Input Shape: (1, 3, 640, 480)

Preprocess:  1.6 ms
Inference:  33.7 ms
Postprocess: 0.9 ms

End-to-end: 41.97 ms \
Memory delta: 0.01 MB

从这组数据可以看到**推理阶段占主导**（interface around 80% of total latency)， 这是典型端侧SoC场景。说明瓶颈主要集中在模型算子执行阶段，而不是 I/O 或后处理。

#### 1 输入分辨率变化
输入的图片的实际尺寸为640X480，而非640X640，这意味着resize / letterbox 发生或memory access pattern 改变。 \
实际端侧视频流往往不是网络默认输入尺寸，因此我同时关注了 preprocess 对整体延迟的影响。

#### 2. 内存几乎不增长
0.01 MB 说明：
- 权重和 buffer 已复用
- 没有额外 graph rebuild
- 推理过程 memory footprint 稳定

这是部署质量好的信号。
# phase 1： YOLOv8n Baseline 推理（Windows + CPU）
在Windows CPU环境下跑通YOLOv8你， 作为端侧部署的baseline
这个阶段不涉及任何SoC特定优化，主要用于建立后续模型转换，量化和算子优化的对比基线

**Q: 为什么不一开始就优化** </br>
因为端侧优化必须建立在可复现，可对比的baseline之上，否则无法量化每一步优化带来的收益

## 分析数据
### 数据1：
写入时间为：2026-01-06 16:19 \
Device: CPU \
Interface Time: 44.56 ms \
Memory Usage: 0.00 MB 

推理结果合理，YOLOv8n在Windows CPU上单张640X640， 40-60ms是常见的区间 \
**Memory Usage 为 0.00 MB** \
原因:
- psutil 读的是 RSS 增量
- YOLO 模型在：
初始化阶段已分配大部分内存;
单次 inference 不再显著增长
- Windows 内存回收策略 + Python GC \
→ 导致 delta ≈ 0

总结：
- 单次推理的内存增量在 Windows 上不明显，**模型参数**和**缓存**主要在*初始化阶段*完成分配，因此 RSS delta 接近 0，这是符合预期的。
- 真正端侧内存评估通常通过工具链统计 peak memory 或 allocator 级别数据，而非 Python 进程 delta

### 数据2：
Input Shape: (1, 3, 640, 480)

Preprocess:  1.6 ms
Inference:  33.7 ms
Postprocess: 0.9 ms

End-to-end: 41.97 ms \
Memory delta: 0.01 MB

从这组数据可以看到**推理阶段占主导**（interface around 80% of total latency)， 这是典型端侧SoC场景。说明瓶颈主要集中在模型算子执行阶段，而不是 I/O 或后处理。

#### 1 输入分辨率变化
输入的图片的实际尺寸为640X480，而非640X640，这意味着resize / letterbox 发生或memory access pattern 改变。 \
实际端侧视频流往往不是网络默认输入尺寸，因此我同时关注了 preprocess 对整体延迟的影响。

#### 2. 内存几乎不增长
0.01 MB 说明：
- 权重和 buffer 已复用
- 没有额外 graph rebuild
- 推理过程 memory footprint 稳定

这是部署质量好的信号。

# Phase2: 模型移植（PyTorch → ONNX）
数据对比

| Backend      | Device | Latency      |
| ------------ | ------ | ------------ |
| PyTorch      | CPU    | ~42–45 ms    |
| ONNX Runtime | CPU    | **37.00 ms** |

这说明什么？

ONNX Runtime 确实减少了 framework overhead
在 CPU-only 场景下：
- graph 优化
- operator scheduling

已经开始起作用

在端侧部署前，首先将 YOLOv8n 从训练框架 PyTorch 导出为 ONNX，作为与硬件无关的中间表示。
在 CPU-only 环境下使用 ONNX Runtime 进行推理验证，结果显示在 640×640 输入下，**推理延迟从约 44 ms 降至 37 ms**，说明 Runtime 层的图优化和算子调度已经带来收益，这也为后续对接 SoC 编译器或 NPU 后端打下基础。

**Q：这一步对 SoC 有什么意义？**

大多数 SoC 的 AI 工具链都是以 ONNX 或类似 IR 作为输入，因此这一步本质上是在验证模型是否“可被 SoC 消化”。

